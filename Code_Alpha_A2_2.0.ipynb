{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Fundamentals Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Training a Classifier\n",
    "=====================\n",
    "\n",
    "We will be defining neural networks, computing loss and updating the weights of the network.\n",
    "\n",
    "----------------\n",
    "Specifically for vision, PyTorch includes a package called\n",
    "``torchvision``, that has data loaders for common datasets such as\n",
    "Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
    "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
    "\n",
    "You can also implement your own dataloader based on ``torch.utils.data.DataLoader``.\n",
    "\n",
    "This provides a huge convenience and avoids writing boilerplate code.\n",
    "\n",
    "We will use the CINIC-10 dataset.\n",
    "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
    "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CINIC-10 are of\n",
    "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "\n",
    "\n",
    "\n",
    "Training an image classifier\n",
    "----------------------------\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolutional Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n",
    "\n",
    "1. Loading and normalizing CIFAR10\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "Using ``torchvision``, it’s extremely easy to load CINIC-10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "cinic_dir = 'D:/MDS/2023/4th Tri-3/DLF/Ass2/DS_10283_3192'\n",
    "traindir = cinic_dir + '/train'\n",
    "validatedir = cinic_dir + '/valid'\n",
    "testdir = cinic_dir + '/test'\n",
    "\n",
    "cinic_mean = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std = [0.24205776, 0.23828046, 0.25874835]\n",
    "normalize = transforms.Normalize(mean=cinic_mean, std=cinic_std)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=cinic_mean, std=cinic_std)\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=cinic_mean, std=cinic_std)\n",
    "])\n",
    "\n",
    "trainset = datasets.ImageFolder(root=traindir, transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2)\n",
    "\n",
    "validateset = datasets.ImageFolder(root=validatedir, transform=transform)\n",
    "validateloader = torch.utils.data.DataLoader(validateset,\n",
    "                                             batch_size=64,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=2)\n",
    "\n",
    "testset = datasets.ImageFolder(root=testdir, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size=64,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=2)\n",
    "\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensuring GPU is being used to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing some training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# select the first 4 images\n",
    "images = images[:4]\n",
    "labels = labels[:4]\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout2d(0.2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv4 = nn.Conv2d(64, 128, 3)\n",
    "        self.conv5 = nn.Conv2d(128, 128, 3)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout2 = nn.Dropout2d(0.2)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 16)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.fc4 = nn.Linear(16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.conv1.weight.device)  # add this line\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # print(x.shape)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # print(x.shape)\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        # print(x.shape)\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "#         self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = x.view(-1, 16 * 5 * 5)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# net = Net()\n",
    "# print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO CHECK THE ERROR OM TORCHVIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #https://torchview.dev/\n",
    "# #https://github.com/mert-kurttutan/torchview\n",
    "from torchview import draw_graph\n",
    "model_graph = draw_graph(net, input_size=(3,32,32), expand_nested=True)\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "net = Net()\n",
    "summary(net, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://appsilon.com/visualize-pytorch-neural-networks/\n",
    "#TODO Visulaize\n",
    "# from torchviz import make_dot\n",
    "\n",
    "# model = Net()\n",
    "# y = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchviz import make_dot\n",
    "# #https://stackoverflow.com/questions/52468956/how-do-i-visualize-a-net-in-pytorch\n",
    "\n",
    "# #Backward pass apparently,\n",
    "# # TODO check on this later\n",
    "# batch = next(iter(dataloader_train))\n",
    "# yhat = model(batch.text) # Give dummy batch to forward().\n",
    "\n",
    "# make_dot(yhat, params=dict(list(model.named_parameters()))).render(\"cnn_torchviz\", format=\"png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hiddenlayer as hl\n",
    "# #https://stackoverflow.com/questions/52468956/how-do-i-visualize-a-net-in-pytorch\n",
    "\n",
    "# #Forward pass apparently,\n",
    "# # TODO check on this later\n",
    "# transforms = [ hl.transforms.Prune('Constant') ] # Removes Constant nodes from graph.\n",
    "\n",
    "# graph = hl.build_graph(model, batch.text, transforms=transforms)\n",
    "# graph.theme = hl.graph.THEMES['blue'].copy()\n",
    "# graph.save('rnn_hiddenlayer', format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.001)\n",
    "# torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "# inputs = inputs.to(device)\n",
    "# outputs = net(inputs)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 10\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    return correct / total\n",
    "             \n",
    "def recall(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    true_positives = ((predicted == labels) & (labels == 1)).sum().item()\n",
    "    false_negatives = ((predicted != labels) & (labels == 1)).sum().item()\n",
    "    denominator = true_positives + false_negatives\n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return true_positives / denominator\n",
    "\n",
    "def precision(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    true_positives = ((predicted == labels) & (labels == 1)).sum().item()\n",
    "    false_positives = ((predicted != labels) & (labels == 0)).sum().item()\n",
    "    denominator = true_positives + false_positives\n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return true_positives / denominator\n",
    "        \n",
    "def train_model_one_epoch(model, trainloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    \n",
    "    result = {'loss': 0,\n",
    "             'accuracy': 0,\n",
    "             'recall': 0,\n",
    "             'precision': 0}\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        result['loss'] += loss.item()\n",
    "        result['accuracy'] += accuracy(outputs, labels)\n",
    "        result['recall'] += recall(outputs, labels)\n",
    "        result['precision'] += precision(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    result = {k: v / len(trainloader) for k, v in result.items()}\n",
    "    return result \n",
    "\n",
    "def valid_model(model, validloader, criterion, device):\n",
    "    result = {'loss': 0,\n",
    "             'accuracy': 0,\n",
    "             'recall': 0,\n",
    "             'precision': 0}\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            result['loss'] += loss.item()\n",
    "            result['accuracy'] += accuracy(outputs, labels)\n",
    "            result['recall'] += recall(outputs, labels)\n",
    "            result['precision'] += precision(outputs, labels)\n",
    "\n",
    "    result = {k: v / len(validloader) for k, v in result.items()}\n",
    "    return result\n",
    "\n",
    "def train_model(model, trainloader, validloader, optimizer, criterion, num_epochs, device):\n",
    "    best_valid_perform = None\n",
    "    train_acc = {}\n",
    "    valid_acc = {}\n",
    "    train_loss = {}\n",
    "    valid_loss = {}\n",
    "    lr = {}\n",
    "    for epoch in range(num_epochs):\n",
    "        train_perform = train_model_one_epoch(model, trainloader, optimizer, criterion, device)\n",
    "        valid_perform = valid_model(model, validloader, criterion, device)\n",
    "        if best_valid_perform is None or valid_perform['accuracy'] > best_valid_perform['accuracy']:\n",
    "            best_valid_perform = valid_perform\n",
    "            torch.save(model.state_dict(), 'best_valid.pt')\n",
    "        print(f'Epoch {epoch+1}: Train Loss={train_perform[\"loss\"]:.4f}, Train Acc={train_perform[\"accuracy\"]:.4f}, Valid Loss={valid_perform[\"loss\"]:.4f}, Valid Acc={valid_perform[\"accuracy\"]:.4f}')\n",
    "        train_acc[epoch+1] = train_perform['accuracy']\n",
    "        valid_acc[epoch+1] = valid_perform['accuracy']\n",
    "        train_loss[epoch+1] = train_perform['loss']\n",
    "        valid_loss[epoch+1] = valid_perform['loss']\n",
    "        lr[epoch+1] = optimizer.param_groups[0]['lr']\n",
    "        train_losses.append(train_perform['loss'])\n",
    "        valid_losses.append(valid_perform['loss'])\n",
    "\n",
    "    show_train_acc(best_valid_perform, train_acc, train_loss, lr)\n",
    "\n",
    "    return train_perform, valid_perform\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "train_perform, valid_perform = train_model(net, trainloader, validateloader, optimizer, criterion, epoch_num, device)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_train_acc(dictionary_best, dictionary_acc, dictionary_loss, dictionary_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cinic_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            if class_total[label] == 0:\n",
    "                class_correct[label] = 0\n",
    "            else:\n",
    "                class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "            correct += c[i].item()\n",
    "            total += 1\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] == 0:\n",
    "        print('Accuracy of %5s : N/A (no test images for this class)' % (classes[i]))\n",
    "    else:\n",
    "        print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "print('Overall accuracy of the network on the test images: %2d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
